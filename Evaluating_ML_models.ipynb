{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate classification models using accuracy, a confusion matrix, precision, and recall\n",
    "### Accuracy: \n",
    "Accuracy quantifies the proportion of accurate predictions among all predictions generated by the model. For instance, in forecasting house prices, accuracy indicates the percentage of accurately forecasted prices among all prices within the data set. It's calculated by determining the proportion of instances that were predicted correctly out of the total instances.\n",
    "\n",
    "\n",
    "$$ Accuracy = (Total number of predictions)/(Number of correct predictions) $$\n",
    "\n",
    "\n",
    "### Confusion matrix: \n",
    "A confusion matrix offers a concise overview of how well a classification model performs. By comparing the model's predictions to the actual outcomes, we determine the counts of true positives, true negatives, false positives, and false negatives. While directly applying a confusion matrix to predicting house prices may seem unconventional due to their continuous nature, you can discretize prices into categories (e.g., cheap, moderate, expensive), and then utilize the confusion matrix to compare predicted categories against actual ones.\n",
    "\n",
    "A confusion matrix provides a summary of prediction results on a classification problem. The matrix shows the counts of true positive (TP), true negative (TN), false positive (FP), and false negative (FN) predictions.\n",
    "\n",
    "Actual/predicted\tHigh price\tLow price\n",
    "High price\tTP\tFN\n",
    "Low price\tFP\tTN\n",
    "\n",
    "| Actual/predicted | High price | Low price|\n",
    "| ----------- | ----------- | ----------- |\n",
    "| High Price | True Positive (TP) | False Negative (FN) |\n",
    "| Low Price | False Positive (FP) | True Negatiev (TN) |\n",
    "\n",
    "### Precision: \n",
    "Precision is how many correct positive predictions the model made out of all its positive predictions. In the realm of house price prediction, precision reflects the accuracy of predicted house prices among all predictions. However, given the continuous nature of house prices, precision is commonly defined within a specific tolerance level. For instance, you might establish a threshold (e.g., within 5% of the actual price) and compute precision based on predictions falling within that range.\n",
    "\n",
    "$$ Precision = (TP)/(TP + FP) $$\n",
    "\n",
    "### Recall: \n",
    "Recall measures how many true positive predictions were made out of all actual positive instances. In the scenario of house price prediction, recall indicates the percentage of accurately predicted house prices among all actual house prices. Typically, recall is defined within a specified tolerance level to accommodate the continuous nature of house prices.\n",
    "\n",
    "$$ Recall = (TP)/(TP + FN) $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate a regression model using mean squared error and other kinds of error terms\n",
    "Evaluating a regression model involves assessing how well the model predicts the target variable. Here, we'll discuss how to evaluate a regression model using mean squared error (MSE) and other error metrics like mean absolute error (MAE), root mean squared error (RMSE), and R-squared (RÂ²).\n",
    "\n",
    "### Mean squared error (MSE):\n",
    "MSE computes the mean of squared errors, representing the average squared disparity (difference) between the estimated values and the actual value.\n",
    "\n",
    "$$\n",
    "\\text{MSE} = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2\n",
    "$$\n",
    "\n",
    "Lower MSE indicates better model performance.\n",
    "\n",
    "### Mean absolute error (MAE):\n",
    "MAE calculates the average size of the errors in a set of predictions, without taking into account their direction.\n",
    "$$\n",
    "\\text{MAE} = \\frac{1}{n} \\sum_{i=1}^{n} \\left| y_i - \\hat{y}_i \\right|\n",
    "$$\n",
    "\n",
    "Lower MAE indicates better model performance.\n",
    "\n",
    "### R-squared (R2):\n",
    "R2 tells us how much of the dependent variable's changes are explained by changes in the independent variables.\n",
    "\n",
    "$$\n",
    "R^2 = 1 - \\frac{\\sum_{i=1}^{n} (y_i - \\bar{y})^2}{\\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2}\n",
    "$$ \n",
    "Higher R2 values, which range from 0 to 1, signify better model performance.\n",
    "\n",
    "### Root mean squared error (RMSE):\n",
    "RMSE, as the square root of MSE, provides an insight into the typical size of errors.\n",
    "\n",
    "$$\n",
    "\\text{RMSE} = \\sqrt{\\text{MSE}} = \\sqrt{\\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2}\n",
    "$$ \n",
    "\n",
    "### Mean absolute percentage error (MAPE):\n",
    "\n",
    "MAPE quantifies accuracy as a percentage of the error.\n",
    "$$\n",
    "\\text{MAPE} = \\frac{1}{n} \\sum_{i=1}^{n} \\left| \\frac{y_i - \\hat{y}_i}{y_i} \\right| \\times 100\n",
    "$$\n",
    "\n",
    "### Median absolute error:\n",
    "* Median absolute error is robust to outliers because it uses the median instead of the mean.\n",
    "* Useful when your data has outliers that could skew the error metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
